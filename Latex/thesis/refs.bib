
@online{zhang_max-planck-institut_2016,
	title = {Max-Planck-Institut für Informatik: Labelled Pupils in the Wild ({LPW})},
	author = {Zhang, Xucong and Sugano, Yusuke and Bulling, Andreas},
	note = {(Accessed: 29.04.2023)},
	date = {2016},
	year = {2016},
	file = {Max-Planck-Institut für Informatik\: Labelled Pupils in the Wild (LPW):C\:\\Users\\Anton Jakob\\Zotero\\storage\\MPPK9XW2\\labelled-pupils-in-the-wild-lpw.html:text/html},
}

@online{noauthor_various_2009,
	title = {Various characteristics of an eye and its iris texture},
	url = {https://www.researchgate.net/figure/Various-characteristics-of-an-eye-and-its-iris-texture-7_fig1_323145066},
	abstract = {Download scientific diagram {\textbar} Various characteristics of an eye and its iris texture [7] from publication: {RANSAC} lens boundary feature based kernel-{SVM} for transparent contact lens detection {\textbar} Transparent contact lens spoofing has been demonstrated to hamper the overall performance of an iris recognition system. Achieving high detection accuracy with transparent lens is quite challenging using iris texture analysis based techniques. In this regard, the authors... {\textbar} Contact Lenses, Lenses and Supervised Learning {\textbar} {ResearchGate}, the professional network for scientists.},
	note = {(Accessed: 29.04.2023)},
	date = {2009},
	year = {2009},
	langid = {english},
	file = {Snapshot:C\:\\Users\\Anton Jakob\\Zotero\\storage\\7IYBZ4U7\\Various-characteristics-of-an-eye-and-its-iris-texture-7_fig1_323145066.html:text/html},
}

@incollection{gonzalez_canny_2018,
	edition = {4},
	title = {Canny Edge Detection},
	pages = {732},
	booktitle = {Digital Image Processing},
	author = {Gonzalez, Rafael C. and Woods, Richard E.},
	date = {2018},
	year = {2018},
}

@incollection{gonzalez_bilinear_2018,
	edition = {4},
	title = {Bilinear Interpolation},
	pages = {77},
	booktitle = {Digital Image Processing},
	author = {Gonzalez, Rafael C. and Woods, Richard E.},
	date = {2018},
	year = {2018},
}

@incollection{gonzalez_edge_2018,
	edition = {4},
	title = {Edge Thining Algorithmus},
	pages = {660},
	booktitle = {Digital Image Processing},
	author = {Gonzalez, Rafael C. and Woods, Richard E.},
	date = {2018},
	year = {2018},
}

@article{viola_rapid_2004,
	title = {Rapid Object Detection using a Boosted Cascade of Simple Features},
	url = {https://www.merl.com/publications/docs/TR2004-043.pdf},
	author = {Viola, Paul and Jones, Michael},
	note = {(Accessed: 18.05.2023)},
	date = {2004},
	year = {2004},
}

@article{swirski_robust_2012,
	title = {Robust real-time pupil tracking in highly off-axis images},
	doi = {10.1145/2168556.2168585},
	abstract = {Robust, accurate, real-time pupil tracking is a key component for online gaze estimation. On head-mounted eye trackers, existing algorithms that rely on circular pupils or contiguous pupil regions fail to detect or accurately track the pupil. This is because the pupil ellipse is often highly eccentric and partially occluded by eyelashes. We present a novel, real-time dark-pupil tracking algorithm that is robust under such conditions. Our approach uses a Haar-like feature detector to roughly estimate the pupil location, performs a k-means segmentation on the surrounding region to refine the pupil centre, and fits an ellipse to the pupil using a novel image-aware Random Sample Concensus ({RANSAC}) ellipse fitting. We compare our approach against existing real-time pupil tracking implementations, using a set of manually labelled infra-red dark-pupil eye images. We show that our technique has a higher pupil detection rate and greater pupil tracking accuracy.},
	pages = {173--176},
	journaltitle = {Eye Tracking Research and Applications Symposium ({ETRA})},
	shortjournal = {Eye Tracking Research and Applications Symposium ({ETRA})},
	author = {Swirski, Lech and Bulling, Andreas and Dodgson, Neil},
	date = {2012-03-01},
	year = {2012},
	file = {Full Text PDF:C\:\\Users\\Anton Jakob\\Zotero\\storage\\EJIZRMH9\\Swirski et al. - 2012 - Robust real-time pupil tracking in highly off-axis.pdf:application/pdf},
}

@article{vondracek_image_2018,
	title = {Image Segmentation Using a Morphological Operator for Curvature-Driven Motion},
	author = {Vondráček, Adam},
	date = {2018},
	year = {2018},
	langid = {english},
	file = {Vondráček - 2018 - Image Segmentation Using a Morphological Operator .pdf:C\:\\Users\\Anton Jakob\\Zotero\\storage\\5GQ3NVXG\\Vondráček - 2018 - Image Segmentation Using a Morphological Operator .pdf:application/pdf},
}

@article{chan_active_2001,
	title = {Active contours without edges},
	volume = {10},
	issn = {1941-0042},
	doi = {10.1109/83.902291},
	abstract = {We propose a new model for active contours to detect objects in a given image, based on techniques of curve evolution, Mumford-Shah (1989) functional for segmentation and level sets. Our model can detect objects whose boundaries are not necessarily defined by the gradient. We minimize an energy which can be seen as a particular case of the minimal partition problem. In the level set formulation, the problem becomes a "mean-curvature flow"-like evolving the active contour, which will stop on the desired boundary. However, the stopping term does not depend on the gradient of the image, as in the classical active contour models, but is instead related to a particular segmentation of the image. We give a numerical algorithm using finite differences. Finally, we present various experimental results and in particular some examples for which the classical snakes methods based on the gradient are not applicable. Also, the initial curve can be anywhere in the image, and interior contours are automatically detected.},
	pages = {266--277},
	number = {2},
	journaltitle = {{IEEE} Transactions on Image Processing},
	author = {Chan, T.F. and Vese, L.A.},
	date = {2001-02},
	year = {2001},
	note = {Conference Name: {IEEE} Transactions on Image Processing},
	keywords = {Active contours, Finite difference methods, Helium, Image edge detection, Image segmentation, Level set, Mathematics, Object detection, Partial differential equations, Two-term control},
	file = {Full Text:C\:\\Users\\Anton Jakob\\Zotero\\storage\\C36R85U3\\Chan and Vese - 2001 - Active contours without edges.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Anton Jakob\\Zotero\\storage\\MS38ITYW\\902291.html:text/html},
}

@article{derpanis_overview_2010,
	title = {Overview of the {RANSAC} Algorithm},
	url = {http://www.cse.yorku.ca/~kosta/CompVis_Notes/ransac.pdf},
	author = {Derpanis, Konstantinos G},
	note = {(Accessed: 24.05.2023)},
	date = {2010},
	year = {2010},
	langid = {english},
	file = {Derpanis - Overview of the RANSAC Algorithm.pdf:C\:\\Users\\Anton Jakob\\Zotero\\storage\\99ULGGCT\\Derpanis - Overview of the RANSAC Algorithm.pdf:application/pdf},
}

@article{kass_snakes_1988,
	title = {Snakes: Active contour models},
	volume = {1},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/10.1007/BF00133570},
	doi = {10.1007/BF00133570},
	shorttitle = {Snakes},
	abstract = {A snake is an energy-minimizing spline guided by external constraint forces and influenced by image forces that pull it toward features such as lines and edges. Snakes are active contour models: they lock onto nearby edges, localizing them accurately. Scale-space continuation can be used to enlarge the capture region surrounding a feature. Snakes provide a unified account of a number of visual problems, including detection of edges, lines, and subjective contours; motion tracking; and stereo matching. We have used snakes successfully for interactive interpretation, in which user-imposed constraint forces guide the snake near features of interest.},
	pages = {321--331},
	number = {4},
	journaltitle = {International Journal of Computer Vision},
	shortjournal = {Int J Comput Vision},
	author = {Kass, Michael and Witkin, Andrew and Terzopoulos, Demetri},
	note = {(Accessed: 24.05.2023)},
	date = {1988},
	year = {1988},
	langid = {english},
	file = {Kass et al. - 1988 - Snakes Active contour models.pdf:C\:\\Users\\Anton Jakob\\Zotero\\storage\\VUKAYP4U\\Kass et al. - 1988 - Snakes Active contour models.pdf:application/pdf},
}

@online{noauthor_opencv_2015,
	title = {{OpenCV}: Histograms, Histogram Equalization},
	url = {https://docs.opencv.org/3.1.0/d5/daf/tutorial_py_histogram_equalization.html},
	note = {(Accessed: 24.05.2023)},
	date = {2015},
	year = {2015},
	file = {OpenCV\: Histograms - 2\: Histogram Equalization:C\:\\Users\\Anton Jakob\\Zotero\\storage\\RALFWLEM\\tutorial_py_histogram_equalization.html:text/html},
}

@inproceedings{tonsen_labelled_2016,
	location = {Charleston South Carolina},
	title = {Labelled pupils in the wild: a dataset for studying pupil detection in unconstrained environments},
	isbn = {978-1-4503-4125-7},
	url = {https://dl.acm.org/doi/10.1145/2857491.2857520},
	doi = {10.1145/2857491.2857520},
	shorttitle = {Labelled pupils in the wild},
	eventtitle = {{ETRA} '16: 2016 Symposium on Eye Tracking Research and Applications},
	pages = {139--142},
	booktitle = {Proceedings of the Ninth Biennial {ACM} Symposium on Eye Tracking Research \& Applications},
	publisher = {{ACM}},
	author = {Tonsen, Marc and Zhang, Xucong and Sugano, Yusuke and Bulling, Andreas},
	note = {(Accesse: 24.05.2023)},
	date = {2016-03-14},
	year = {2016},
	langid = {english},
	file = {Submitted Version:C\:\\Users\\Anton Jakob\\Zotero\\storage\\HJ8IPZY7\\Tonsen et al. - 2016 - Labelled pupils in the wild a dataset for studyin.pdf:application/pdf},
}

@incollection{gonzalez_sharpening_2018,
	edition = {4},
	title = {Sharpening (Highpass) Spatial Filters},
	pages = {184},
	booktitle = {Digital Image Processing},
	author = {Gonzalez, Rafael C. and Woods, Richard E.},
	date = {2018},
	year = {2018},
}

@article{fitzgibbon_direct_2000,
	title = {Direct Least Square Fitting of Ellipses},
	volume = {21},
	doi = {10.1109/34.765658},
	abstract = {This work presents a new efficient method for fitting ellipses to scattered data. Previous algorithms either fitted general conics or were computationally expensive. By minimizing the algebraic distance subject to the constraint4ac ; b =1 the new method incorporates the ellipticity constraint into the normalization factor. The proposed method combines several advantages: (i) It is ellipse-specific so that even bad data will always return an ellipse\# (ii) It can be solved naturally by a generalized eigensystem and (iii) it is extremely robust, efficient and easy to implement.},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	shortjournal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Fitzgibbon, Andrew and Pilu, Maurizio and Fisher, Robert},
	date = {2000-11-09},
	year = {2000},
	file = {Full Text PDF:C\:\\Users\\Anton Jakob\\Zotero\\storage\\49R4VGH7\\Fitzgibbon et al. - 2000 - Direct Least Square Fitting of Ellipses.pdf:application/pdf},
}

@article{gander_least_1980,
	title = {Least squares with a quadratic constraint},
	volume = {36},
	issn = {0945-3245},
	url = {https://doi.org/10.1007/BF01396656},
	doi = {10.1007/BF01396656},
	abstract = {We present the theory of the linear least squares problem with a quadratic constraint. New theorems characterizing properties of the solutions are given. A numerical application is discussed.},
	pages = {291--307},
	number = {3},
	journaltitle = {Numerische Mathematik},
	shortjournal = {Numer. Math.},
	author = {Gander, Walter},
	note = {(Accessed: 29.05.2023)},
	date = {1980-09-01},
	year = {1980},
	langid = {english},
	keywords = {{AMS}({MOS}): 65F20, {CR}: 5.14},
	file = {Full Text PDF:C\:\\Users\\Anton Jakob\\Zotero\\storage\\YNQ2WCIL\\Gander - 1980 - Least squares with a quadratic constraint.pdf:application/pdf},
}

@incollection{drahansky_recognition_2018,
	location = {Rijeka},
	title = {Recognition of Eye Characteristics},
	url = {https://doi.org/10.5772/intechopen.76026},
	booktitle = {Machine Learning and Biometrics},
	publisher = {{IntechOpen}},
	author = {Drahanský, Martin},
	editor = {Yang, Jucheng and Park, Dong Sun and Yoon, Sook and Chen, Yarui and Zhang, Chuanlei},
	date = {2018},
	note = {(Accessed: 29.05.2023)},
	year = {2018},
	doi = {10.5772/intechopen.76026},

}

@article{arar_robust_2017,
	title = {Robust Eye Tracking Based on Adaptive Fusion of Multiple Cameras},
	url = {http://infoscience.epfl.ch/record/231152},
	doi = {https://doi.org/10.5075/epfl-thesis-7933},
	abstract = {Eye and gaze movements play an essential role in identifying individuals' emotional states, cognitive activities, interests, and attention among other behavioral traits. Besides, they are natural, fast, and implicitly reflect the targets of interest, which makes them a highly valuable input modality in human-computer interfaces. Therefore, tracking gaze movements, in other words, eye tracking is of great interest to a large number of disciplines, including human behaviour research, neuroscience, medicine, and human-computer interaction. Tracking gaze movements accurately is a challenging task, especially under unconstrained conditions. Over the last two decades, significant advances have been made in improving the gaze estimation accuracy. However, these improvements have been achieved mostly under controlled settings. Meanwhile, several concerns have arisen, such as the complexity, inflexibility and cost of the setups, increased user effort, and high sensitivity to varying real-world conditions. Despite various attempts and promising enhancements, existing eye tracking systems are still inadequate to overcome most of these concerns, which prevent them from being widely used. In this thesis, we revisit these concerns and introduce a novel multi-camera eye tracking framework. The proposed framework achieves a high estimation accuracy while requiring a minimal user effort and a non-intrusive flexible setup. In addition, it provides improved robustness to large head movements, illumination changes, use of eye wear, and eye type variations across users. We develop a novel real-time gaze estimation framework based on adaptive fusion of multiple single-camera systems, in which the gaze estimation relies on projective geometry. Besides, to ease the user calibration procedure, we investigate several methods to model the subject-specific estimation bias, and consequently, propose a novel approach based on weighted regularized least squares regression. The proposed method provides a better calibration modeling than state-of-the-art methods, particularly when using low-resolution and limited calibration data. Being able to operate with low-resolution data also enables to utilize a large field-of-view setup, so that large head movements are allowed. To address aforementioned robustness concerns, we propose to leverage multiple eye appearances simultaneously acquired from various views. In comparison with conventional single view approach, the main benefit of our approach is to more reliably detect gaze features under challenging conditions, especially when they are obstructed due to large head pose or movements, or eye glasses effects. We further propose an adaptive fusion mechanism to effectively combine the gaze outputs obtained from multi-view appearances. To this effect, our mechanism firstly determines the estimation reliability of each gaze output and then performs a reliability-based weighted fusion to compute the overall point of regard. In addition, to address illumination and eye type robustness, the setup is built upon active illumination and robust feature detection methods are developed. The proposed framework and methods are validated through extensive simulations and user experiments featuring 20 subjects. The results demonstrate that our framework provides not only a significant improvement in gaze estimation accuracy but also a notable robustness to real-world conditions, making it suitable for a large spectrum of applications.},
	pages = {167},
	author = {Arar, Nuri Murat},
	note = {(Accessed: 29.05.2023)},
	date = {2017},
	year = {2017},
	note = {Backup Publisher: {IEL}
Place: Lausanne
Publisher: {EPFL}},
}

@article{wildes_iris_1997,
	title = {Iris recognition: an emerging biometric technology},
	volume = {85},
	issn = {1558-2256},
	doi = {10.1109/5.628669},
	abstract = {This paper examines automated iris recognition as a biometrically based technology for personal identification and verification. The motivation for this endeavor stems from the observation that the human iris provides a particularly interesting structure on which to base a technology for noninvasive biometric assessment. In particular the biomedical literature suggests that irises are as distinct as fingerprints or patterns of retinal blood vessels. Further, since the iris is an overt body, its appearance is amenable to remote examination with the aid of a machine vision system. The body of this paper details issues in the design and operation of such systems. For the sake of illustration, extant systems are described in some amount of detail.},
	pages = {1348--1363},
	number = {9},
	journaltitle = {Proceedings of the {IEEE}},
	author = {Wildes, R.P.},
	date = {1997-09},
	year = {1997},
}

@inproceedings{chao_long_2016,
	title = {Long short term memory recurrent neural network based encoding method for emotion recognition in video},
	doi = {10.1109/ICASSP.2016.7472178},
	abstract = {Human emotion is a temporally dynamic event which can be inferred from both audio and video feature sequences. In this paper we investigate the long short term memory recurrent neural network ({LSTM}-{RNN}) based encoding method for category emotion recognition in the video. {LSTM}-{RNN} is able to incorporate knowledge about how emotion evolves over long range successive frames and emotion clues from isolated frame. After encoding, each video clip can be represented by a vector for each input feature sequence. The vectors contain both frame level and sequence level emotion information. These vectors are then concatenated and fed into support vector machine ({SVM}) to get the final prediction result. Extensive evaluations on Emotion Challenge in the Wild ({EmotiW}2015) dataset show the efficiency of the proposed encoding method and competitive results are obtained. The final recognition accuracy achieves 46.38\% for audio-video emotion recognition sub-challenge, where the challenge baseline is 39.33\%.},
	pages = {2752--2756},
	booktitle = {2016 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	author = {Chao, Linlin and Tao, Jianhua and Yang, Minghao and Li, Ya and Wen, Zhengqi},
	date = {2016-03},
	year = {2016},
	note = {{ISSN}: 2379-190X},
}

@inproceedings{zheng_multimodal_2014,
	title = {Multimodal emotion recognition using {EEG} and eye tracking data},
	doi = {10.1109/EMBC.2014.6944757},
	abstract = {This paper presents a new emotion recognition method which combines electroencephalograph ({EEG}) signals and pupillary response collected from eye tracker. We select 15 emotional film clips of 3 categories (positive, neutral and negative). The {EEG} signals and eye tracking data of five participants are recorded, simultaneously, while watching these videos. We extract emotion-relevant features from {EEG} signals and eye tracing data of 12 experiments and build a fusion model to improve the performance of emotion recognition. The best average accuracies based on {EEG} signals and eye tracking data are 71.77\% and 58.90\%, respectively. We also achieve average accuracies of 73.59\% and 72.98\% for feature level fusion strategy and decision level fusion strategy, respectively. These results show that both feature level fusion and decision level fusion combining {EEG} signals and eye tracking data can improve the performance of emotion recognition model.},
	pages = {5040--5043},
	booktitle = {2014 36th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society},
	author = {Zheng, Wei-Long and Dong, Bo-Nan and Lu, Bao-Liang},
	date = {2014-08},
	year = {2014},
	note = {{ISSN}: 1558-4615},
}

@inproceedings{grubisic_natural_2014,
	title = {Natural eye gaze computer interaction for medical oculography diagnosis: Current status and future prospects},
	doi = {10.1109/MIPRO.2014.6859603},
	abstract = {With recent technological developments, modern computing systems are becoming more and more powerful. Common computers are capable of calculating more than 50,000 million instructions per second. Currently the biggest obstacle in computer usage is slow communication between the human and the computer. With innovation and development of novel (natural based) sensors capable of capturing positions and natural motion of human body a new, natural, way of interacting with computer is enabled. This paper gives an overview of eye tracking technology, and presents its application in nature based human-computer interaction ({HCI}) systems by extending standard controllers, such as the keyboard and the mouse. Novel approaches enable {HCI} closer to the communication patterns of human beings. In addition, the usage of those concepts in applications for eye diseases and disorders diagnostics and rehabilitation is discussed.},
	pages = {421--425},
	booktitle = {2014 37th International Convention on Information and Communication Technology, Electronics and Microelectronics ({MIPRO})},
	author = {Grubiśić, I. and Grbeśa, I. and Lipic, T. and Skala, K. and Zrinscak, O. and Ivekovic, R. and Vatavuk, Z.},
	date = {2014-05},
	year = {2014},
}
